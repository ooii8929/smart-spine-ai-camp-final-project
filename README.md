# 姿優生 - 快速使用指南

參考論文：
1. https://learnopencv.com/building-a-body-posture-analysis-system-using-mediapipe/

影像
  ↓
PoseNet 偵測 17 個關鍵點[1]（不是 MediaPipe！）
  ↓
提取特徵（關鍵點座標 + 影像區域特徵）
  ↓
展平成 14739 維特徵向量
  ↓
你的神經網路分類器
  ↓
輸出：[正確的: 85%, 錯誤的: 15%]


[1] **PoseNet 的 17 個關鍵點：**
```
0: 鼻子
1-2: 左右眼
3-4: 左右耳
5-6: 左右肩膀
7-8: 左右手肘
9-10: 左右手腕
11-12: 左右臀部
13-14: 左右膝蓋
15-16: 左右腳踝



### 3. **你的模型結構**
```
輸入層: 14739 個特徵
   ↓
全連接層 1: 100 個神經元 (ReLU 激活)
   ↓
Dropout: 50% (防止過擬合)
   ↓
全連接層 2: 2 個神經元 (Softmax 激活)
   ↓
輸出: [正確的機率, 錯誤的機率]
```

**這是一個簡單的分類器：**
- 輸入：14739 個特徵
- 輸出：2 個類別的機率

其他參考資料：https://learnopencv.com/building-a-body-posture-analysis-system-using-mediapipe/
Dataset:
https://dayta.nwu.ac.za/articles/dataset/Human_pose_dataset_sit_stand_pose_classes_/23290937
https://arxiv.org/html/2412.12216v1
https://medium.com/@andy6804tw/%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8Byolo-%E5%88%A9%E7%94%A8-roboflow-%E5%92%8C-ultralytics-hub-%E5%AE%8C%E6%88%90%E6%A8%A1%E5%9E%8B%E8%A8%93%E7%B7%B4%E8%88%87%E7%AE%A1%E7%90%86-%E4%B8%8A-37acd110a8a0
https://ieeexplore.ieee.org/document/10901866
https://universe.roboflow.com/min-bnvzi/sitting-posture-v2
https://teachablemachine.withgoogle.com/train/pose

## 📦 檔案說明

1. **posture_detection_architecture.docx** - 完整的產品設計架構文件
   - 包含系統架構圖、技術規格、功能設計
   - 詳細的開發文件和擴展規劃

2. **posture_detection.html** - 可直接執行的完整程式
   - 單一 HTML 檔案，包含所有功能
   - 無需安裝任何軟體，開啟即可使用

## 🚀 快速開始

### 方法一：直接開啟（最簡單）
1. 找到 `posture_detection.html` 檔案
2. 雙擊開啟（會用預設瀏覽器開啟）
3. 允許瀏覽器使用攝影機
4. 點擊「開始偵測」按鈕
5. 完成！

### 方法二：本地伺服器（推薦用於開發）
```bash
# 進入檔案所在目錄
cd /path/to/your/files

# 使用 Python 啟動簡單的 HTTP 伺服器
python -m http.server 8000

# 或使用 Node.js 的 http-server
npx http-server -p 8000
```

然後在瀏覽器開啟 `http://localhost:8000/posture_detection.html`

## 💡 使用建議

### 環境設置
- ✅ 充足的光線（避免背光）
- ✅ 攝影機正對使用者
- ✅ 距離攝影機 50-100 公分
- ✅ 穿著對比明顯的衣服

### 功能說明

#### 即時監測區
- 🎥 **視訊畫面**：顯示攝影機即時畫面
- 🔴/🟢 **狀態指示**：綠色=正確，紅色=錯誤
- 🦴 **骨架顯示**：標示身體關鍵點和連線

#### 數據面板
- **肩膀水平度**：應 < 10° 才算正確
- **背部角度**：應在 75-105° 之間
- **頭部前傾**：數值越低越好
- **偵測信心度**：模型對偵測結果的信心

#### 統計資訊
- **總時間**：使用系統的總秒數
- **正確時間**：維持正確坐姿的秒數
- **錯誤時間**：姿勢不正確的秒數
- **正確率**：正確時間的百分比

#### 改善建議
系統會即時提供改善建議，例如：
- "肩膀不平衡，請調整坐姿"
- "身體前傾過多，請坐直"
- "頭部前傾過多，請將頭部往後移"

### 按鈕功能
- **開始偵測**：啟動/停止即時偵測
- **重置統計**：清除所有統計數據，重新開始

## 🎯 坐姿標準

### ✅ 正確坐姿特徵
1. **肩膀水平**：兩肩齊平，不歪斜
2. **背部挺直**：背部與椅背成 90-100 度
3. **頭部居中**：不前傾、不後仰
4. **身體平衡**：重心在正中，不側傾

### ❌ 常見錯誤姿勢
1. **駝背**：背部過度彎曲
2. **前傾**：整個身體往前倒
3. **歪斜**：肩膀一高一低
4. **低頭**：頭部過度前傾

## 🔧 系統需求

### 最低需求
- **瀏覽器**：Chrome 90+、Edge 90+、Safari 14+、Firefox 88+
- **攝影機**：640x480 解析度，15 FPS
- **處理器**：Intel i3 或同等級
- **記憶體**：4GB RAM
- **網路**：首次使用需要連網（下載模型）

### 建議規格
- **瀏覽器**：最新版 Chrome 或 Edge
- **攝影機**：1280x720 解析度，30 FPS
- **處理器**：Intel i5 / AMD Ryzen 5 或更高
- **記憶體**：8GB RAM 或更多
- **網路**：5Mbps 或更快

## 🐛 常見問題

### 1. 攝影機無法啟動
**解決方法：**
- 檢查瀏覽器是否有攝影機權限
- 確認沒有其他程式正在使用攝影機
- 嘗試重新整理頁面

### 2. 偵測不準確
**可能原因：**
- 光線不足或背光
- 穿著與背景顏色太接近
- 距離攝影機太遠或太近
- 身體部分被遮擋

**解決方法：**
- 調整光線和位置
- 更換對比明顯的衣服
- 確保全身（至少上半身）完整入鏡

### 3. 畫面延遲或卡頓
**解決方法：**
- 關閉其他耗資源的程式
- 降低瀏覽器視窗大小
- 確認電腦效能符合需求

### 4. 提示「攝影機存取失敗」
**解決方法：**
1. 檢查瀏覽器設定
   - Chrome: 設定 > 隱私權與安全性 > 網站設定 > 攝影機
   - 確認該網站有攝影機權限
2. 檢查作業系統設定
   - Windows: 設定 > 隱私權 > 攝影機
   - macOS: 系統偏好設定 > 安全性與隱私權 > 攝影機
3. 重新啟動瀏覽器

## 📚 技術說明

### 使用的技術
- **MediaPipe Pose**：Google 開發的人體姿態估計模型
- **Canvas API**：用於繪製骨架和視覺化
- **WebRTC getUserMedia**：取得攝影機串流
- **純前端架構**：無需後端伺服器

### 關鍵演算法
1. **關鍵點偵測**：MediaPipe 偵測 33 個身體關鍵點
2. **角度計算**：使用向量計算身體各部位角度
3. **姿勢判斷**：根據預設閾值判斷坐姿正確性
4. **視覺化渲染**：即時繪製骨架和狀態

### 隱私保護
- ✅ 所有運算在本地進行
- ✅ 不上傳任何影像或數據
- ✅ 不儲存個人資訊
- ✅ 關閉視窗即停止使用攝影機

## 🎓 延伸學習

### 想要了解更多？
1. 閱讀 `posture_detection_architecture.docx` 了解完整架構
2. 查看 HTML 原始碼學習實作細節
3. 參考 MediaPipe 官方文件進行客製化

### 可能的改進方向
- 新增語音提醒功能
- 支援多人同時偵測
- 加入機器學習個人化調整
- 開發手機 APP 版本
- 整合健康追蹤系統

## 📞 技術支援

如有任何問題或建議，歡迎提供反饋！

---

**版本：** 1.0  
**最後更新：** 2026-01-31  
**開發者：** Claude AI Assistant
